
@article{artetxe_massively_2019,
  title = {Massively {{Multilingual Sentence Embeddings}} for {{Zero-Shot Cross-Lingual Transfer}} and {{Beyond}}},
  author = {Artetxe, Mikel and Schwenk, Holger},
  date = {2019},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  volume = {7},
  pages = {597--610},
  doi = {10.1162/tacl_a_00288},
  abstract = {We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts. Our system uses a single BiLSTM encoder with a shared byte-pair encoding vocabulary for all languages, which is coupled with an auxiliary decoder and trained on publicly available parallel corpora. This enables us to learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification. Our experiments in cross-lingual natural language inference (XNLI data set), cross-lingual document classification (MLDoc data set), and parallel corpus mining (BUCC data set) show the effectiveness of our approach. We also introduce a new test set of aligned sentences in 112 languages, and show that our sentence embeddings obtain strong results in multilingual similarity search even for low- resource languages. Our implementation, the pre-trained encoder, and the multilingual test set are available at https://github.com/facebookresearch/LASER .},
  langid = {english},
}

@article{chan_reproducible_2020,
  title = {Reproducible {{Extraction}} of {{Cross-Lingual Topics}} (Rectr)},
  author = {Chan, Chung-Hong and Zeng, Jing and Wessler, Hartmut and Jungblut, Marc and Welbers, Kasper and Bajjalieh, Joseph W. and van Atteveldt, Wouter and Althaus, Scott L.},
  options = {useprefix=true},
  date = {2020},
  journaltitle = {Communication Methods and Measures},
  volume = {14},
  number = {4},
  pages = {285--305},
  doi = {10.1080/19312458.2020.1812555},
  abstract = {With global media content databases and online content being available, analyzing topical structures in different languages simultaneously has become an urgent computational task. Some previous studies have analyzed topics in a multilingual corpus by translating all items into a single language using a machine translation service, such as Google Translate. We argue that this method is not reproducible in the long run and proposes a new method – Reproducible Extraction of Cross-lingual Topics Using R (rectr). Our method utilizes open-source-aligned word embeddings to understand the cross-lingual meanings of words and has a mechanism to normalize residual influence from language differences. We present a benchmark that compares the topics extracted from a corpus of English, German, and French news using our method with methods used in the literature. We show that our method is not only reproducible but can also generate high-quality cross-lingual topics. We demonstrate how our method can be applied in tracking news topics across time and languages.}
}

@article{courtney_automatic_2020,
  title = {Automatic Translation, Context, and Supervised Learning in Comparative Politics},
  author = {Courtney, Michael and Breen, Michael and McMenamin, Iain and McNulty, Gemma},
  date = {2020},
  journaltitle = {Journal of Information Technology \& Politics},
  volume = {17},
  number = {3},
  pages = {208--217},
  doi = {10.1080/19331681.2020.1731245},
  abstract = {This paper proves that automatic translation of multilingual newspaper documents deters neither human nor computer classification of political concepts. We show how theory-driven coding of newspaper text can be automated in several languages by monolingual researchers. Supervised machine learning is successfully applied to text in English from British, Spanish, and German sources. The paper has three main findings. First, results from human coding directly in a foreign language do not differ from coding computer-translated text. Second, humans can code translated text as well as they can code untranslated prose in their mother tongue. Third, machine learning based on translated Spanish and German training sets can reproduce human coding as accurately as a system learning from English training sets.},
}

@unpublished{dai_multilingual_2019,
  title = {Multilingual {{Word Embedding}} for {{Zero-Shot Text Classification}}},
  author = {Dai, Yaoyao and Radford, Benjamin J.},
  date = {2019},
  url = {https://yaoyaodai.github.io/files/Dai_0BlinC.pdf},
  abstract = {For years political scientists have been developing tools to analyze text data, motivated by both the richness and wide availability of unstructured text as well as by the limited availability of accurate structured data. However, while many research questions are comparative and cross-national, we lack methods for analyzing multilingual corpora. Political scientists typically analyze texts from multilingual corpora separately and within the contexts of each individual language or by translating all texts into a common language before performing analysis. In this paper, we develop a Zero-shot Bilingual Classifier (0-BlinC), a novel multitask feed-forward neural network that utilizes cross-lingual information to facilitate text classification in multilingual corpora. Using a parallel bilingual corpus and training data in a single source language, 0-BlinC can perform quasi-sentence-level text classification in a target language for which no training labels are available. We demonstrate our method by measuring policy positions of party manifestos in English, Spanish, Bulgarian, Estonian, Italian, German and French using labeled text in English only. 0-BlinC is shown to outperform alternative methods that include the use of a machine translation service and pre-trained word vectors.},
  langid = {english},
  file = {/Users/licht/Zotero/storage/FM9T7KJ4/Dai - Multilingual Word Embedding for Zero-Shot Text Cla.pdf}
}

@article{de_vries_no_2018,
  title = {No Longer Lost in Translation: {{Evidence}} That Google Translate Works for Comparative Bag-of-Words Text Applications},
  author = {de Vries, Erik and Schoonvelde, Martijn and Schumacher, Gijs},
  options = {useprefix=true},
  date = {2018},
  journaltitle = {Political Analysis},
  volume = {26},
  number = {4},
  pages = {417--430},
  publisher = {{Cambridge University Press (CUP)}},
  doi = {10.1017/pan.2018.26},
}

@article{dupont_ties_2021,
  title = {The {{Ties That Bind}}: {{Text Similarities}} and {{Conditional Diffusion}} among {{Parties}}},
  shorttitle = {The {{Ties That Bind}}},
  author = {Düpont, Nils and Rachuj, Martin},
  date = {2022},
  journaltitle = {British Journal of Political Science},
  volume = {52},
  number = {2},
  pages = {613--630},
  doi = {10.1017/S0007123420000617},
  abstract = {Comparative analyses of party policy diffusion are only just emerging. To better understand the conditions under which diffusion occurs, this article argues that three heuristics – availability, representativeness and anchoring – shape parties' efforts to gather information (from elsewhere), leading to differing diffusion effects. The study operationalizes the outcome as textual similarity of party manifestos in nineteen Western democracies from 1960 to 2016, applying a text-as-data approach and machine translation. Analyzing dyads, it assesses how commonalities and sender/receiver attributes impact diffusion. It finds that there is little room for cross-border diffusion as successful parties stick to their old program. Beyond the still-prevailing domestic context, 'learning from cultural reference groups' in a region is most important. In addition, diffusion appears within EP factions and transnational party organizations independently of the success/loss of the sender. The analysis thus sheds light on (un-)favorable conditions for party policy diffusion and paves the way for future studies applying machine translation and quantitative text analyses.},
  langid = {english},
}

@unpublished{fan_beyond_2020-arxiv,
  title = {Beyond {{English-Centric Multilingual Machine Translation}}},
  author = {Fan, Angela and Bhosale, Shruti and Schwenk, Holger and Ma, Zhiyi and El-Kishky, Ahmed and Goyal, Siddharth and Baines, Mandeep and Celebi, Onur and Wenzek, Guillaume and Chaudhary, Vishrav and Goyal, Naman and Birch, Tom and Liptchinsky, Vitaliy and Edunov, Sergey and Grave, Edouard and Auli, Michael and Joulin, Armand},
  date = {2020},
  eprint = {2010.11125},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2010.11125},
  abstract = {Existing work in translation demonstrated the potential of massively multilingual machine translation by training a single model able to translate between any pair of languages. However, much of this work is English-Centric by training only on data which was translated from or to English. While this is supported by large sources of training data, it does not reflect translation needs worldwide. In this work, we create a true Many-to-Many multilingual translation model that can translate directly between any pair of 100 languages. We build and open source a training dataset that covers thousands of language directions with supervised data, created through large-scale mining. Then, we explore how to effectively increase model capacity through a combination of dense scaling and language-specific sparse parameters to create high quality models. Our focus on non-English-Centric models brings gains of more than 10 BLEU when directly translating between non-English directions while performing competitively to the best single systems of WMT. We open-source our scripts so that others may reproduce the data, evaluation, and final M2M-100 model.},
  archiveprefix = {arXiv},
}

@inproceedings{glavas_cross-lingual_2017,
  title = {Cross-{{Lingual Classification}} of {{Topics}} in {{Political Texts}}},
  booktitle = {Proceedings of the {{Second Workshop}} on {{NLP}} and {{Computational Social Science}}},
  author = {Glavaš, Goran and Nanni, Federico and Ponzetto, Simone Paolo},
  date = {2017},
  pages = {42--46},
  doi = {10.18653/v1/W17-2906},
  abstract = {In this paper, we propose an approach for cross-lingual topical coding of sentences from electoral manifestos of political parties in different languages. To this end, we exploit continuous semantic text representations and induce a joint multilingual semantic vector spaces to enable supervised learning using manually-coded sentences across different languages. Our experimental results show that classifiers trained on multilingual data yield performance boosts over monolingual topic classification.},
}

@inproceedings{glavas_unsupervised_2017,
  title = {Unsupervised {{Cross-Lingual Scaling}} of {{Political Texts}}},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Volume}} 2, {{Short Papers}}},
  author = {Glavaš, Goran and Nanni, Federico and Ponzetto, Simone Paolo},
  date = {2017},
  pages = {688--693},
  url = {https://www.aclweb.org/anthology/E17-2109},
  abstract = {Political text scaling aims to linearly order parties and politicians across political dimensions (e.g., left-to-right ideology) based on textual content (e.g., politician speeches or party manifestos). Existing models scale texts based on relative word usage and cannot be used for cross-lingual analyses. Additionally, there is little quantitative evidence that the output of these models correlates with common political dimensions like left-to-right orientation. Experimental results show that the semantically-informed scaling models better predict the party positions than the existing word-based models in two different political dimensions. Furthermore, the proposed models exhibit no drop in performance in the cross-lingual compared to monolingual setting.}
}

@thesis{goist_radical_2020,
  type = {phdthesis},
  title = {The {{Radical Right}} in {{Parliament}}: {{A}} New Method and Application for Studying Political Text in Multiple Languages},
  shorttitle = {The {{Radical Right}} in {{Parliament}}},
  author = {Goist, Mitchell},
  date = {2020},
  url = {https://etda.libraries.psu.edu/catalog/17825mlg307},
  abstract = {Since a new wave of radical right support in the early 1980s, scholars have sought to understand the motivations and programmatic appeals of far-right parties. However, due to their small size and dearth of data, existing methodological approaches were did not allow the direct study of these parties' behavior in parliament. Using a collection of parliamentary speeches from the United Kingdom, Germany, Spain, Italy, the Netherlands, Finland, Sweden, and the Czech Republic, Chapter 1 of this dissertation addresses this problem by developing a new model for the study of political text in multiple languages. Using this new method allows the construction of a shared issue space where each party is embedded regardless of the language spoken in the speech or the country of origin. Chapter 2 builds on this new method by explicating the ideological appeals of radical right parties. It finds that in some instances radical right parties behave similarly to mainstream, center-right parties, but distinguish themselves by a focus on individual crime and an emphasis on negative rhetorical frames. The chapter further illustrates how radical right populist appeals differ from leftist populist appeals, through the latter's emphasis on material deprivation. Finally, Chapter 3 shows how mainstream parties react to increases in radical right support, finding that they engage in rhetorical concessions, attempting to mimic the radical right's rhetoric while granting fewer substantive concessions. This chapter provides evidence for a "coarsening" of debate that can arise after radical right entry into parliament.},
  langid = {english}
}

@article{hillard_computer-assisted_2008,
  title = {Computer-{{Assisted Topic Classification}} for {{Mixed-Methods Social Science Research}}},
  author = {Hillard, Dustin and Purpura, Stephen and Wilkerson, John},
  date = {2008},
  journaltitle = {Journal of Information Technology \& Politics},
  volume = {4},
  number = {4},
  pages = {31--46},
  doi = {10.1080/19331680801975367},
  abstract = {Social scientists interested in mixed-methods research have traditionally turned to human annotators to classify the documents or events used in their analyses. The rapid growth of digitized government documents in recent years presents new opportunities for research but also new challenges. With more and more data coming online, relying on human annotators becomes prohibitively expensive for many tasks. For researchers interested in saving time and money while maintaining confidence in their results, we show how a particular supervised learning system can provide estimates of the class of each document (or event). This system maintains high classification accuracy and provides accurate estimates of document proportions, while achieving reliability levels associated with human efforts. We estimate that it lowers the costs of classifying large numbers of complex documents by 80\% or more.},
}

@article{lehmann_positions_2018,
  title = {Positions and Saliency of Immigration in Party Manifestos: {{A}} Novel Dataset Using Crowd Coding},
  author = {Lehmann, Pola and Zobel, Malisa},
  journaltitle = {European Journal of Political Research},
  date = {2018},
  volume = {57},
  number = {4},
  pages = {1056--1083},
}

@unpublished{licht_cross-lingual_2022-wp,
  title = {Cross-Lingual Classification of Political Texts Using Multilingual Sentence Embeddings},
  author = {Licht, Hauke},
  date = {2022},
  url = {https://osf.io/384wr/?view_only=abcfb31cada64dbca8f7b43a59b1e696},
  abstract = {Established approaches to analyze multilingual text corpora require either a duplication of analysts' efforts or high-quality machine translation (MT). In this paper, I argue that multilingual sentence embedding (MSE) is an attractive alternative approach to language-independent text representation. To support this argument, I evaluate MSE for cross-lingual supervised text classification. Specifically, I assess how reliably MSE-based classifiers detect manifesto sentences' topics and positions compared to classifiers trained using bag-of-words representations of machine-translated texts, and how this depends on the amount of training data. These analyses show that when training data is relatively scarce (e.g. 20K or less labeled sentences), MSE-based classifiers can be more reliable and are at least no less reliable than their MT-based counterparts. Further, I examine how reliable MSE-based classifiers label sentences written in languages not in the training data, focusing on the task of discriminating sentences that discuss the issue of immigration from those that do not. This analysis shows that compared to the within-language classification benchmark, such "cross-lingual transfer" tends to result in fewer reliability losses when relying on the MSE instead of the MT approach. This study thus presents an important addition to the cross-lingual text analysis toolkit.}
}

@article{lind_building_2021,
  title = {Building the {{Bridge}}: {{Topic Modeling}} for {{Comparative Research}}},
  shorttitle = {Building the {{Bridge}}},
  author = {Lind, Fabienne and Eberl, Jakob-Moritz and Eisele, Olga and Heidenreich, Tobias and Galyga, Sebastian and Boomgaarden, Hajo G.},
  date = {2021},
  journaltitle = {Communication Methods and Measures},
  volume = {First View},
  pages = {1--19},
  doi = {10.1080/19312458.2021.1965973},
  abstract = {In communication research, topic modeling is primarily used for discovering systematic patterns in monolingual text corpora. To advance the usage, we provide an overview of recently presented strategies to extract topics from multilingual text collections for the purpose of comparative research. Moreover, we discuss, demonstrate, and facilitate the usability of the “Polylingual Topic Model” (PLTM) for such analyses. The appeal of this model is that it derives lists of related clustered words in different languages with little reliance on translation or multilingual dictionaries and without the need for manual post-hoc matching of topics. PLTM bridges the gap between languages by making use of document connections in training documents. As these training documents are the crucial resource for the model, we compare model evaluation metrics for different strategies to build training documents. By discussing the advantages and limitations of the different strategies in respect to different scenarios, our study contributes to the methodological discussion on automated content analysis of multilingual text corpora.},
}

@article{lucas_computer-assisted_2015,
  title = {Computer-Assisted Text Analysis for Comparative Politics},
  author = {Lucas, Christopher and Nielsen, Richard A and Roberts, Margaret E and Stewart, Brandon M and Storer, Alex and Tingley, Dustin},
  date = {2015},
  volume = {23},
  number = {2},
  pages = {254--277},
  doi = {10.1093/pan/mpu019},
  abstract = {Recent advances in research tools for the systematic analysis of textual data are enabling exciting new research throughout the social sciences. For comparative politics, scholars who are often interested in non-English and possibly multilingual textual datasets, these advances may be difficult to access. This article discusses practical issues that arise in the processing, management, translation, and analysis of textual data with a particular focus on how procedures differ across languages. These procedures are combined in two applied examples of automated text analysis using the recently introduced Structural Topic Model. We also show how the model can be used to analyze data that have been translated into a single language via machine translation tools. All the methods we describe here are implemented in open-source software packages available from the authors.},
}

@article{osnabrugge_cross-domain_2021,
  title = {Cross-{{Domain Topic Classification}} for {{Political Texts}}},
  author = {Osnabrügge, Moritz and Ash, Elliott and Morelli, Massimo},
  date = {2021},
  journaltitle = {Political Analysis},
  volume = {First view},
  pages = {1--22},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/pan.2021.37},
  abstract = {We introduce and assess the use of supervised learning in cross-domain topic classification. In this approach, an algorithm learns to classify topics in a labeled source corpus and then extrapolates topics in an unlabeled target corpus from another domain. The ability to use existing training data makes this method significantly more efficient than within-domain supervised learning. It also has three advantages over unsupervised topic models: the method can be more specifically targeted to a research question and the resulting topics are easier to validate and interpret. We demonstrate the method using the case of labeled party platforms (source corpus) and unlabeled parliamentary speeches (target corpus). In addition to the standard within-domain error metrics, we further validate the cross-domain performance by labeling a subset of target-corpus documents. We find that the classifier accurately assigns topics in the parliamentary speeches, although accuracy varies substantially by topic. We also propose tools diagnosing cross-domain classification. To illustrate the usefulness of the method, we present two case studies on how electoral rules and the gender of parliamentarians influence the choice of speech topics.},
  langid = {english},
}

@inproceedings{radford_attributing_2021,
  title = {Attributing {{Policy Influence}} in {{Multilingual Setting}} Using {{Semantic Textual Similarity}}},
  author = {Radford, Benjamin J. and Dai, Yaoyao and Golder, Matt},
  date = {2021},
  eventtitle = {2021 {{Annual Meeting}} of the {{American Political Science Asociation}} ({{APSA}})}
}

@article{reber_overcoming_2018,
  title = {Overcoming Language Barriers: {{Assessing}} the Potential of Machine Translation and Topic Modeling for the Comparative Analysis of Multilingual Text Corpora},
  author = {Reber, Ueli},
  date = {2018},
  journaltitle = {Communication Methods and Measures},
  volume = {13},
  number = {2},
  pages = {102--125},
  publisher = {{Informa UK Limited}},
  doi = {10.1080/19312458.2018.1555798},
}

@inproceedings{reimers_making_2020,
  title = {Making {{Monolingual Sentence Embeddings Multilingual}} Using {{Knowledge Distillation}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  date = {2020},
  pages = {4512--4525},
  doi = {10.18653/v1/2020.emnlp-main.365},
  abstract = {Nils Reimers, Iryna Gurevych. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.},
  eventtitle = {Empirical {{Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  langid = {american}
}

@article{ruder_survey_2019,
  title = {A {{Survey Of Cross-lingual Word Embedding Models}}},
  author = {Ruder, Sebastian and Vulić, Ivan and Søgaard, Anders},
  date = {2019},
  journaltitle = {Journal of Artificial Intelligence Research},
  volume = {65},
  eprint = {1706.04902},
  eprinttype = {arxiv},
  pages = {569--631},
  doi = {10.1613/jair.1.11640},
  abstract = {Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.},
  archiveprefix = {arXiv},
}

@article{windsor_automated_2019,
  title = {Automated Content Analysis across Six Languages},
  author = {Windsor, Leah Cathryn and Cupit, James Grayson and Windsor, Alistair James},
  date = {2019},
  journaltitle = {PloS One},
  volume = {14},
  number = {11},
  pages = {e0224425},
  doi = {10.1371/journal.pone.0224425},
  abstract = {Corpus selection bias in international relations research presents an epistemological problem: How do we know what we know? Most social science research in the field of text analytics relies on English language corpora, biasing our ability to understand international phenomena. To address the issue of corpus selection bias, we introduce results that suggest that machine translation may be used to address non-English sources. We use human translation and machine translation (Google Translate) on a collection of aligned sentences from United Nations documents extracted from the Multi-UN corpus, analyzed with a "bag of words" analysis tool, Linguistic Inquiry Word Count (LIWC). Overall, the LIWC indices proved relatively stable across machine and human translated sentences. We find that while there are statistically significant differences between the original and translated documents, the effect sizes are relatively small, especially when looking at psychological processes.},
  langid = {english},
}


